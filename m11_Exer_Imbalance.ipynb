{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# EXCERCISE: IMBALANCE CLASSIFICATION "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Masih menggunakan Loan dataset, kombinasikan hyperparameter tuning cv dengan metode: \n",
    "* Resampling: Undersampling\n",
    "* Penalized \n",
    "\n",
    "email ke Brigita.gems@gmail.com  \n",
    "subject: imbalance classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "pada data bankloan ini, kita mencari nilai f1 score, dengan tujuan:\n",
    "-  mengurangi yg diprediksi gagal bayar, padahal bisa bayar. ini adalah calon customer\n",
    "- mengurangi yg diprediksi bisa bayar, padahal ga mampu bayar. ini bikin rugi perusahaan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  ed  employ  address  income  debtinc   creddebt   othdebt  default\n",
       "0   41   3      17       12     176      9.3  11.359392  5.008608        1\n",
       "1   27   1      10        6      31     17.3   1.362202  4.000798        0\n",
       "2   40   1      15       14      55      5.5   0.856075  2.168925        0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>ed</th>\n      <th>employ</th>\n      <th>address</th>\n      <th>income</th>\n      <th>debtinc</th>\n      <th>creddebt</th>\n      <th>othdebt</th>\n      <th>default</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>3</td>\n      <td>17</td>\n      <td>12</td>\n      <td>176</td>\n      <td>9.3</td>\n      <td>11.359392</td>\n      <td>5.008608</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27</td>\n      <td>1</td>\n      <td>10</td>\n      <td>6</td>\n      <td>31</td>\n      <td>17.3</td>\n      <td>1.362202</td>\n      <td>4.000798</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40</td>\n      <td>1</td>\n      <td>15</td>\n      <td>14</td>\n      <td>55</td>\n      <td>5.5</td>\n      <td>0.856075</td>\n      <td>2.168925</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "bankloan = pd.read_csv('bankloan.csv')\n",
    "bankloan.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitur = ['employ', 'debtinc', 'creddebt', 'othdebt']\n",
    "target = 'default'\n",
    "\n",
    "X = bankloan[fitur]\n",
    "y = bankloan[target]"
   ]
  },
  {
   "source": [
    "## EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    73.857143\n",
       "1    26.142857\n",
       "Name: default, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "bankloan['default'].value_counts()/bankloan.shape[0]*100"
   ]
  },
  {
   "source": [
    "## Data Splitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data dibagi 2: train_val dan test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    stratify = y,\n",
    "    test_size = 0.2, \n",
    "    random_state = 1899)\n",
    "\n",
    "# # ini untuk threshold\n",
    "# # train_val dibagi 2: train dan val \n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train_val,\n",
    "#     y_train_val, \n",
    "#     stratify = y_train_val,\n",
    "#     test_size = 0.25, \n",
    "#     random_state = 1899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. BENCHMARK Default\n",
    "\n",
    "- tanpa resampling method\n",
    "- tanpa menggunakan hyperparameter tuning (before)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Benchmark report:\n              precision    recall  f1-score   support\n\n           0       0.81      0.93      0.87       103\n           1       0.68      0.41      0.51        37\n\n    accuracy                           0.79       140\n   macro avg       0.75      0.67      0.69       140\nweighted avg       0.78      0.79      0.77       140\n\n"
     ]
    }
   ],
   "source": [
    "# fitting dengan train_val set\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_val, y_train_val)\n",
    "\n",
    "# predict dengan test set\n",
    "y_pred_1 = logreg.predict(X_test)\n",
    "\n",
    "# classification report\n",
    "print('Benchmark report:')\n",
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 2. Resampling: Undersampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM CHAIN\n",
    "\n",
    "# balancing\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# pipeline\n",
    "estimator = Pipeline([('balancing', rus), ('clf', model)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.73      0.82       103\n           1       0.53      0.84      0.65        37\n\n    accuracy                           0.76       140\n   macro avg       0.73      0.78      0.73       140\nweighted avg       0.82      0.76      0.77       140\n\n"
     ]
    }
   ],
   "source": [
    "# fitting model dengan set yg sudah diundersampling (dgn estimator) \n",
    "estimator.fit(X_train_val, y_train_val)\n",
    "\n",
    "# predict model\n",
    "y_pred_2 = estimator.predict(X_test)\n",
    "\n",
    "# classification report\n",
    "print('Undersampling report:')\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 3. Penalized"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Penalized report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.72      0.82       103\n           1       0.53      0.89      0.67        37\n\n    accuracy                           0.76       140\n   macro avg       0.74      0.81      0.74       140\nweighted avg       0.84      0.76      0.78       140\n\n"
     ]
    }
   ],
   "source": [
    "# fitting model dengan penalized\n",
    "model_balanced = LogisticRegression(class_weight='balanced')\n",
    "model_balanced.fit(X_train_val, y_train_val)\n",
    "\n",
    "# predict model\n",
    "y_pred_3 = model_balanced.predict(X_test)\n",
    "\n",
    "# classification report\n",
    "print('Penalized report:')\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 4. Resampling (Undersampling) dengan Hyperparameter Tuning "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm Chain\n",
    "\n",
    "rus = RandomUnderSampler() # resampling\n",
    "model = LogisticRegression() # model\n",
    "estimator = Pipeline([('balancing',rus),('clf',model)]) \n",
    "\n",
    "# Hyperparameter space\n",
    "hyperparam_space = {\n",
    "    'clf__C':[100, 10, 1, 0.1, 0.01, 0.001],\n",
    "    'clf__solver':['liblinear', 'newton-cg']\n",
    "}\n",
    "\n",
    "# Stratified cross validation (berapa kali cross val)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator, # menggunakan model, ambilnya dari estimator\n",
    "    param_grid = hyperparam_space, # untuk isi parameter, ambil dari Hyperparameter space\n",
    "    cv = skf, # mau berapa kali cross validation\n",
    "    scoring = 'f1', # kita mencari f1 score\n",
    "    n_jobs = -1 # menggunakan all cores\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('balancing', RandomUnderSampler()),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
       "                         'clf__solver': ['liblinear', 'newton-cg']},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "# fitting model yg sudah di-hyperparameter tuning\n",
    "grid_search.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best score: 0.6242486297043421\nbest param: {'clf__C': 0.01, 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# melihat best score dan best parameter\n",
    "print('best score:', grid_search.best_score_)\n",
    "print('best param:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('balancing', RandomUnderSampler()),\n                ('clf', LogisticRegression(C=0.01, solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "# melihat best estimator (sama kaya best_params_ di atas)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "y_pred_4 = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling after Hyperparameter Tuning\n              precision    recall  f1-score   support\n\n           0       0.91      0.62      0.74       103\n           1       0.44      0.84      0.58        37\n\n    accuracy                           0.68       140\n   macro avg       0.68      0.73      0.66       140\nweighted avg       0.79      0.68      0.70       140\n\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print('Undersampling after Hyperparameter Tuning')\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 5. Penalized dengan Hyperparameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_balanced = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# hyperparameter space\n",
    "hyperparam_space = {\n",
    "    'C':[100, 10, 1, 0.1, 0.01, 0.001], \n",
    "    'solver':['liblinear','newton-cg']  \n",
    "}\n",
    "\n",
    "# stratified cross validation\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "# hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    model_balanced, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skf, # hyperparameter space\n",
    "    scoring ='f1', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
       "             param_grid={'C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
       "                         'solver': ['liblinear', 'newton-cg']},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "# fitting model yg sudah di-hyperparameter tuning\n",
    "grid_search.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best score: 0.6220290204014038\nbest param: {'C': 0.01, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# melihat best score dan best parameter\n",
    "print('best score:', grid_search.best_score_)\n",
    "print('best param:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', solver='liblinear')"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_5 = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Undersampling after Hyperparameter Tuning\n              precision    recall  f1-score   support\n\n           0       0.93      0.66      0.77       103\n           1       0.48      0.86      0.62        37\n\n    accuracy                           0.71       140\n   macro avg       0.70      0.76      0.69       140\nweighted avg       0.81      0.71      0.73       140\n\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print('Undersampling after Hyperparameter Tuning')\n",
    "print(classification_report(y_test, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# SUMMARY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_1 = f1_score(y_test, y_pred_1)\n",
    "f1_2 = f1_score(y_test, y_pred_2)\n",
    "f1_3 = f1_score(y_test, y_pred_3)\n",
    "f1_4 = f1_score(y_test, y_pred_4)\n",
    "f1_5 = f1_score(y_test, y_pred_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     method     score\n",
       "0                   Default  0.508475\n",
       "1             Undersampling  0.645833\n",
       "2                 Penalized  0.666667\n",
       "3  Undersampling dgn Tuning  0.579439\n",
       "4      Penalized dgn Tuning  0.615385"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>method</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Default</td>\n      <td>0.508475</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Undersampling</td>\n      <td>0.645833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Penalized</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Undersampling dgn Tuning</td>\n      <td>0.579439</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Penalized dgn Tuning</td>\n      <td>0.615385</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "score_list = [f1_1, f1_2, f1_3, f1_4, f1_5] \n",
    "model_names = ['Default','Undersampling','Penalized','Undersampling dgn Tuning', 'Penalized dgn Tuning']\n",
    "df_summary = pd.DataFrame({\n",
    "    'method':model_names,\n",
    "    'score':score_list\n",
    "})\n",
    "df_summary"
   ]
  },
  {
   "source": [
    "# Kesimpulan\n",
    "\n",
    "Model paling baik berdasarkan f1 score nya adalah dengan Penalized yg class_weight (algo based) tanpa Hyperparameter tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# TAHAP MELAKUKAN MACHINE LEARNING:\n",
    "\n",
    "1. Explore Data : datanya mau diapain, tentukan target data, dan tipe machine learning yg cocok\n",
    "\n",
    "2. Preprocessing : handling missing data dan outlier (ini bisa juga dilakukan saat explore data). scaling, encoding, feature engineering (ex:polynomial),  feature selaction jika diperlukan.\n",
    "\n",
    "3. Pemilihan model: dengan cross validation, untuk memmilh model yg stabil dan performa maksimum.\n",
    "\n",
    "4. Optimasi model: imbalance classification, hyperparameter tuning.\n",
    "\n",
    "5. Evaluasi : mencari model dengan performa optimum. kalau hasil evaluasi kurang memuaskan, kembali ke step2 sebelumnya.\n",
    "\n",
    "pro tip: proses preprocessing-optimasi lebih baik dilakukan dengan pipeline untuk mencegah data leakage (algoritm chain, model evaluation method)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}