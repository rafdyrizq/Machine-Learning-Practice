{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BOOSTING EXCERCISE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Tugas: Gunakan titanic.csv untuk mencoba boosting model.\n",
    "* Splitting: 80-20, stratify: y, random state 2020\n",
    "\n",
    "* Preprocessing: \n",
    ">* drop deck\n",
    ">* Isi missing value (age, embarked town) menggunakan simple imputer \n",
    ">* onehot encoding: sex, alone, class, embarked town  \n",
    "\n",
    "* evaluation metric yang dipakai: F1_score\n",
    "* model selection: Decision Tree Classifier, AdaBoost Classifier, GBoost Classifier, XGBoost Classifier.\n",
    "* Hyperparameter tunning model yang terpilih.\n",
    "* Buat summary untuk hasil evaluasi, dan kesimpulan mana model yang terbaik untuk titanic.csv\n",
    "\n",
    "protip: gunakan pipeline dan function ketika memungkinkan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      sex   age  parch     fare  class deck  embark_town alive  alone\n",
       "0    male  22.0      0   7.2500  Third  NaN  Southampton    no  False\n",
       "1  female  38.0      0  71.2833  First    C    Cherbourg   yes  False\n",
       "2  female  26.0      0   7.9250  Third  NaN  Southampton   yes   True"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>age</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alive</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n      <td>no</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>yes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n      <td>yes</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 9 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   sex          891 non-null    object \n 1   age          714 non-null    float64\n 2   parch        891 non-null    int64  \n 3   fare         891 non-null    float64\n 4   class        891 non-null    object \n 5   deck         203 non-null    object \n 6   embark_town  889 non-null    object \n 7   alive        891 non-null    object \n 8   alone        891 non-null    bool   \ndtypes: bool(1), float64(2), int64(1), object(5)\nmemory usage: 56.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              age       parch        fare\n",
       "count  714.000000  891.000000  891.000000\n",
       "mean    29.699118    0.381594   32.204208\n",
       "std     14.526497    0.806057   49.693429\n",
       "min      0.420000    0.000000    0.000000\n",
       "25%     20.125000    0.000000    7.910400\n",
       "50%     28.000000    0.000000   14.454200\n",
       "75%     38.000000    0.000000   31.000000\n",
       "max     80.000000    6.000000  512.329200"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>parch</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29.699118</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.526497</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>80.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sex              0\n",
       "age            177\n",
       "parch            0\n",
       "fare             0\n",
       "class            0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 1. Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Drop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column 'deck' karena missing value terlalu banyak\n",
    "df = df.drop(columns='deck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Pipeline dan Transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline berisi imputing lalu onehot encoding untuk 'embark_town' nanti\n",
    "embark_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one hot encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# transformer \n",
    "transformer = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(strategy='median'), ['age']),\n",
    "    ('embark_pipeline', embark_pipeline, ['embark_town']),\n",
    "    ('one hot encoder', OneHotEncoder(drop='first'), ['sex','alone','class'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Split Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      sex   age  parch     fare  class  embark_town  alone  label\n",
       "0    male  22.0      0   7.2500  Third  Southampton  False      0\n",
       "1  female  38.0      0  71.2833  First    Cherbourg  False      1\n",
       "2  female  26.0      0   7.9250  Third  Southampton   True      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>age</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>embark_town</th>\n      <th>alone</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>Southampton</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>Cherbourg</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>Southampton</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# ganti target ('alive') jadi 0-1 ('label)\n",
    "df['label'] = np.where(df['alive']=='yes', 1, 0)\n",
    "\n",
    "# drop column 'alive'\n",
    "df = df.drop(columns='alive')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X dan y\n",
    "# X drop alive dan label\n",
    "X = df.drop(columns='label')\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "# X_train di sini maksudnya adalah X_train_val\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    stratify=y,\n",
    "    test_size=0.2,\n",
    "    random_state=2020\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 2. Model Selection\n",
    "\n",
    "termasuk sekalian Data Transforming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* evaluation metric yang dipakai: F1_score\n",
    "* model selection: Decision Tree Classifier, AdaBoost Classifier, GBoost Classifier, XGBoost Classifier.\n",
    "* Hyperparameter tunning model yang terpilih.\n",
    "* Buat summary untuk hasil evaluasi, dan kesimpulan mana model yang terbaik untuk titanic.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DecsionTree\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Adaboost\n",
    "ada = AdaBoostClassifier(\n",
    "    tree,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=10 \n",
    ")\n",
    "\n",
    "# Gradientboost\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=10 \n",
    ")\n",
    "\n",
    "# ExtremeGradientBosst\n",
    "xgbc = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=10 \n",
    ")\n"
   ]
  },
  {
   "source": [
    "## Data Transforming and Fitting\n",
    "tanpa cross validation (seharusnya pakai)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline untuk Data Transforming and Fitting\n",
    "\n",
    "tree_pipeline = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', tree)\n",
    "])\n",
    "\n",
    "ada_pipeline = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', ada)\n",
    "])\n",
    "\n",
    "gbc_pipeline = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', gbc)\n",
    "])\n",
    "\n",
    "xgbc_pipeline = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', xgbc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dan Predict Data\n",
    "\n",
    "def classification(model):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Classification Report')\n",
    "    return print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report\n              precision    recall  f1-score   support\n\n           0       0.80      0.85      0.82       110\n           1       0.73      0.67      0.70        69\n\n    accuracy                           0.78       179\n   macro avg       0.77      0.76      0.76       179\nweighted avg       0.77      0.78      0.77       179\n\n"
     ]
    }
   ],
   "source": [
    "# DecsionTree\n",
    "classification(tree_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report\n              precision    recall  f1-score   support\n\n           0       0.78      0.83      0.81       110\n           1       0.70      0.64      0.67        69\n\n    accuracy                           0.75       179\n   macro avg       0.74      0.73      0.74       179\nweighted avg       0.75      0.75      0.75       179\n\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "classification(ada_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report\n              precision    recall  f1-score   support\n\n           0       0.80      0.93      0.86       110\n           1       0.85      0.64      0.73        69\n\n    accuracy                           0.82       179\n   macro avg       0.82      0.78      0.79       179\nweighted avg       0.82      0.82      0.81       179\n\n"
     ]
    }
   ],
   "source": [
    "# GradientBoost\n",
    "classification(gbc_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[08:33:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       110\n",
      "           1       0.81      0.68      0.74        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.79      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ExtremeGradientBoost\n",
    "classification(xgbc_pipeline)"
   ]
  },
  {
   "source": [
    "## Kesimpulan Berdasarkan F1 Score\n",
    "\n",
    "### model terbaik adalah ExtremeGradientBoost (xgbc)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Model Selection dengan GridSearch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline untuk transformer/preprocessing dan model\n",
    "estimator = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', tree)\n",
    "])\n",
    "\n",
    "# memilih model terbaik\n",
    "hyperparam_space = {\n",
    "    'clf':[tree, ada, gbc, xgbc]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skfold (berapa kali cross validation)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator,\n",
    "    param_grid = hyperparam_space,\n",
    "    cv = skf,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'f1'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('transformer',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('imputer',\n",
       "                                                                         SimpleImputer(strategy='median'),\n",
       "                                                                         ['age']),\n",
       "                                                                        ('embark_pipeline',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('one '\n",
       "                                                                                          'hot '\n",
       "                                                                                          'encoder',\n",
       "                                                                                          OneHotEncoder(dr...\n",
       "                                               gpu_id=-1,\n",
       "                                               importance_type='gain',\n",
       "                                               interaction_constraints='',\n",
       "                                               learning_rate=0.1,\n",
       "                                               max_delta_step=0, max_depth=3,\n",
       "                                               min_child_weight=1, missing=nan,\n",
       "                                               monotone_constraints='()',\n",
       "                                               n_estimators=200, n_jobs=4,\n",
       "                                               num_parallel_tree=1,\n",
       "                                               random_state=10, reg_alpha=0,\n",
       "                                               reg_lambda=1, scale_pos_weight=1,\n",
       "                                               subsample=1, tree_method='exact',\n",
       "                                               validate_parameters=1,\n",
       "                                               verbosity=None)]},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# fit data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score_ 0.7578484352351057\nbest_params_ {'clf': GradientBoostingClassifier(n_estimators=200, random_state=10)}\n"
     ]
    }
   ],
   "source": [
    "# melihat best score dan best parameter\n",
    "print('best_score_', grid_search.best_score_)\n",
    "print('best_params_', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median'),\n",
       "                                                  ['age']),\n",
       "                                                 ('embark_pipeline',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['embark_town']),\n",
       "                                                 ('one hot encoder',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['sex', 'alone', 'class'])])),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(n_estimators=200,\n",
       "                                            random_state=10))])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# fit data dengan model terbaik dari random_search\n",
    "grid_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.80      0.93      0.86       110\n           1       0.85      0.64      0.73        69\n\n    accuracy                           0.82       179\n   macro avg       0.82      0.78      0.79       179\nweighted avg       0.82      0.82      0.81       179\n\n"
     ]
    }
   ],
   "source": [
    "# Predict data\n",
    "y_pred_gbc = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# lihat f1 score nya\n",
    "print(classification_report(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Kesimpulan Model Terbaik dengan Random Search\n",
    "\n",
    "model terbaik adalah:\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=200, random_state=10)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 3. Hyperparameter Tuning pada Gradient Boost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline untuk model gradient boost\n",
    "estimator_gbc = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('clf', gbc)\n",
    "])\n",
    "\n",
    "# hyperparam space\n",
    "hyperparam_space=[\n",
    "    {'clf__learning_rate':[0.1],'clf__n_estimators':[200]},\n",
    "    {'clf__learning_rate':[0.05],'clf__n_estimators':[400]},\n",
    "    {'clf__learning_rate':[0.01],'clf__n_estimators':[2000]},\n",
    "    {'clf__learning_rate':[0.005],'clf__n_estimators':[4000]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skfold (berapa kali cross validation)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Random Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator_gbc,\n",
    "    param_distributions = hyperparam_space,\n",
    "    cv = skf,\n",
    "    n_jobs = -1,\n",
    "    scoring = 'f1'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('transformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('imputer',\n",
       "                                                                               SimpleImputer(strategy='median'),\n",
       "                                                                               ['age']),\n",
       "                                                                              ('embark_pipeline',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                               ('one '\n",
       "                                                                                                'hot '\n",
       "                                                                                                'encoder',\n",
       "                                                                                                OneHotEnco...\n",
       "                                                                                'class'])])),\n",
       "                                             ('clf',\n",
       "                                              GradientBoostingClassifier(n_estimators=200,\n",
       "                                                                         random_state=10))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions=[{'clf__learning_rate': [0.1],\n",
       "                                         'clf__n_estimators': [200]},\n",
       "                                        {'clf__learning_rate': [0.05],\n",
       "                                         'clf__n_estimators': [400]},\n",
       "                                        {'clf__learning_rate': [0.01],\n",
       "                                         'clf__n_estimators': [2000]},\n",
       "                                        {'clf__learning_rate': [0.005],\n",
       "                                         'clf__n_estimators': [4000]}],\n",
       "                   scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# fit data dengan random_search\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score_ 0.765613903455513\nbest_params_ {'clf__n_estimators': 400, 'clf__learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# melihat best score dan best parameter pada GradientBoost\n",
    "print('best_score_', random_search.best_score_)\n",
    "print('best_params_', random_search.best_params_)"
   ]
  },
  {
   "source": [
    "## Terakhir, Predict data dengan: \n",
    "### Model dan Parameter setelah hyperparameter tuning (atau dirangkum dengan best_estimator)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median'),\n",
       "                                                  ['age']),\n",
       "                                                 ('embark_pipeline',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['embark_town']),\n",
       "                                                 ('one hot encoder',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['sex', 'alone', 'class'])])),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                            n_estimators=400,\n",
       "                                            random_state=10))])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.80      0.93      0.86       110\n           1       0.84      0.62      0.72        69\n\n    accuracy                           0.81       179\n   macro avg       0.82      0.78      0.79       179\nweighted avg       0.81      0.81      0.80       179\n\n"
     ]
    }
   ],
   "source": [
    "y_pred_gbc_tuning = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_gbc_tuning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Kesimpulan\n",
    "\n",
    "### Hyperparameter tidak meningkatkan performa model\n",
    "\n",
    "- f1 score XGBC tanpa random search : 0.74 (ini gak pake cross validation)\n",
    "- f1 score GBC dengan random search : 0.73\n",
    "- f1 score GBC after tuning : 0.72\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}